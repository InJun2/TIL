# Ssafy System Design Book Study Week2

## 독서 중 흥미로운 부분

### 4. 처리율 제한 장치의 설계
- 처리율 제한 장치는 클라이언트 측일 수 있고 서버측 장치일 수 있으며 또한 서버측으로 전송되는 중 미들웨어에 위치할 수 있음
    - 하지만 클라이언트 측이라면 처리율 제한을 안정적으로 걸 수 있는 장소가 되지 못함
    - 클라이언트 요청은 쉽게 위변조가 가능하고 모든 클라이언트의 구현을 통제하는 것도 어려울 수 있음
- 처리율 제한 알고리즘은 다음과 같음
    - 토큰 버킷 알고리즘 : 엔드포인트마다 버킷을 할당해 해당 버킷이 충분히 존재하는 경우에만 요청 수행
    - 누출 버킷 알고리즘 : 토큰 버킷 알고리즘과 유사하지만 요청 처리율이 고정되어 큐로 구현되어 큐가 가득 차있다면 새로운 요청을 버림
    - 고정 윈도 카운터 알고리즘 : 타임라인을 고정된 간격의 윈도로 나누고 각 윈도마다 카운터를 붙임. 하지만 해당 지정 타임 라인이 중간에 초기화 되면 특정 부분에서만 작업이 많이 처리 될 수 있음
    - 이동 윈도 로깅 알고리즘 : 고정 윈도 카운터 알고리즘을 보완한 방법으로 이전 요청의 타임 스탬프 시간을 통해 허용한도가 가득찼다면 해당 시간 차이가 지정된 시간이상 차이가 난다면 이전 타임 스탬프를 만료
    - 이동 윈도 카운터 알고리즘 : 고정 윈도 카운터와 이동 윈도 로깅을 합친 방법
- 처리율 제한 알고리즘의 기본 아이디어는 얼마나 많은 요청이 접수되었는지 추적할 수 있는 카운터를 사용자 별로, API 별로, IP 주소별로, API 엔드 포인트나 서비스 단위로 할지 또한, 카운터의 값이 초과된다면 요청을 거부하는 것
    - 또한 해당 카운터를 어디에 보관할지
- 처리율 한도에 대한 정보 (클라이언트 요청이 처리율 제한에 걸리고 있는지, 혹은 요청이 처리율 제한이 걸리기까지 보낼 수 있는 요청)등을 해당 헤더들을 통해 HTTP 응답헤더로 전송, 또한 처리율 한도가 초과될 경우 실패 응답코드는 429 도 함께 전송
    - X-Ratelimit-Remaining : 윈도 내에 남은 처리 가능 요청의 수
    - X-Ratelimit-Limit : 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
    - X-Ratelimit-Retry-After : 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림
- 처리율 제한 규칙은 디스크에 보관하되 작업 프로세스는 수시로 규칙을 디스크에서 읽어 캐시에 저장
- 분산 환경에서의 처리율 제한 장치 구현의 큰 문제는 경쟁 조건과 동기화 문제
    - 경쟁 조건 : 주요 락을 사용하되 성능이 상당히 떨어져 루아 스크립트 및 정렬 집합인 레디스 자료구조를 추천
    - 동기화 : 대규모 시스템의 경우 하나의 처리율 제한 장치로는 충분하지 않을 수 있으며 해당 경우 처리율 제한 장치끼리의 동기화가 필요해짐. 이를 중앙 집중형 데이터 저장소를 사용해 해소


<br>

### 5. 안정 해시 설계
- 해시 키 재배치(rehash) 문제
    - N개의 캐시 서버가 있을 때 서버의 부하를 균등하게 나누는 보편적인 방법은 해시 값을 N 모듈러 연산을 통한 서버 분배
    - 하지만 기존 서버가 장애를 일으켜 동작을 중단했을 때 데이터가 없는 엉뚱한 서버에 접속하게 되어 대규모 캐시 미스가 발생함
- 안정 해시 (consistent hash)
    - 위의 해시 모듈러 연산 시 발생하는 문제를 해결한 기술
    - 해시 테이블 크기가 조정될 때 평균적으로 k/n 개의 키만 재배치 하는 기술
- 안정 해시의 동작 원리를 SHA-1 을 사용한다고 했을 때
    - 해시 공간의 범위는 0 ~ 2^160 -1 까지 있고 이를 원형으로 해시 링을 구성
    - 서버를 해당 범위에 배치하되 모듈러 연산은 하지 않음
    - 이후 특정 키가 해당 범위에 추가되었다면 시계 방향으로 순회하여 가장 근처에 있는 서버에 저장됨
    - 하지만 해당 경우 하나의 서버가 삭제되면 다음 서버가 비교적 많은 데이터를 저장해야 하는 문제 발생
- 이를 해결하기 위한 균등 분포(uniform distribution)
    - 위의 문제는 서버가 추가되거나 삭제되면 파티션의 크기를 균등하게 유지하는게 불가능
    - 두번째 문제는 균등 분포가 어려워 서버 사이가 좁고 해당 서버에 데이터가 많이 들어가지 않게 되어 균등 분포를 달성하기 어려움
    - 이를 해결하기 위해 가상 노드(virtual node) 또는 복제 노드(replica node)를 사용
- 가상 노드
    - 실제 노드 또는 서버를 가리키는 노드로서 하나의 서버는 링 위에 여러 개의 가상 노드를 가질 수 있음
    - 한 서버가 여러 파티션의 가상 노드를 해시 링에 배치하여 균등하게 분포하는 방법
    - 가상 노드가 많으면 균등하게 분포되어 표준 편차 값이 떨어지지만 가상 노드 저장할 공간은 많이 필요하게 되어 개수를 적절히 조정해야 함
    - 서버가 추가되어 노드가 배치했다면 반시계 방향으로 다음 노드까지 존재하는 키를 데이터를 추가된 노드에 저장해야 하므로 해당 범위 재배치
    - 서버가 삭제되어 노드가 제거됬다면 삭제된 노드 기준 반시계 방향의 노드들을 다음 노드에 저장해야 하므로 해당 범위 재배치


<br>

### 모르겠는 부분
#### 1. 루아 스크립트 및 정렬 집합인 레디스 자료구조
- 모든 Lua 스크립트는 실행될 때 다른 명령어가 중간에 끼어들 수 없기 때문에 데이터의 무결성을 보장할 수 있음
- 여러 명령어를 조합한 복잡한 작업을 하나의 Lua 스크립트로 작성하여 원자적으로 실행하거나, 조건문과 반복문 등을 활용해 데이터 처리를 효율적으로 할 수 있음
- 작고 가벼워서 실행이 빠르고 효율적이며 테이블이란 타입이 간편하지만 다른 언어처럼 확장 기능이 거의 없음

- 정렬 집합(Sorted Set)은 Redis의 주요 자료구조 중 하나로 점수(score)에 따라 요소를 자동으로 정렬하는 기능을 제공
- 각 요소는 고유한 값과 함께 점수를 가지고 있으며, 이 점수에 의해 오름차순으로 정렬함
    - [Redis Sorted Set 사용 명령어](https://redis.io/docs/latest/commands/zadd/)

<br>

#### 2. 처리율 제한 장치를 클라이언트에서 설계할 때 재시도(retry) 로직을 구현할 때는 충분한 백오프(back-off) 시간을 둔다?
- 백오프(back-off) 시간
    - 요청이 실패했을 때 재시도 사이의 시간을 점차 늘려가는 방식
    - 첫 번째 재시도는 1초, 두 번째는 2초, 세 번째는 4초 등으로 점진적으로 대기 시간을 늘려가며 재시도
    - 실패한 요청에 대해 다시 시도할 때 올바른 응답을 받기 위한 방법
    - 무분별한 재시도는 서버 과부하를 초래할 수 있으며, 네트워크 트래픽을 낭비

<br>

#### 3. 특정 샤드에 대한 접근이 빈번하면 문제가 발생 시 핫스팟 키 감소
- 핫스팟(Hot spot)은 분산 시스템에서 특정 데이터나 서버에 너무 많은 요청이 집중되는 상황
- 샤딩(Sharding)이란 대용량 데이터를 관리하기 위해 데이터를 여러 개의 샤드(Shard)로 나누는 과정
- 샤드란 분할된 데이터가 저장되는 개별적인 데이터베이스나 파티션
- 데이터를 물리적으로 나누어서 여러 개의 서버나 파티션에 분배하는 것
- 샤딩은 보통 데이터를 어떤 기준에 따라 나누어서 저장하며 각각의 샤드는 독립적인 데이터베이스처럼 동작하며, 특정 샤드에 저장된 데이터는 그 샤드에서만 관리됨