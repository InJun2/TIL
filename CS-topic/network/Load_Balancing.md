# Load Balancing 

<br>

![Load Balancer](./img/loadbalancing.png)

<br>

### 로드밸런싱 (Load Balancing)
- 네트워크 또는 서버에 가해지는 로드를 분산해주는 기술
- 부하가 심해져 병목현상이 생기는 것을 방지하기 위해 사용
- 컴퓨팅 리소스, 네트워크 리소스 등 모든 부분에서의 성능향상을 기대함
- 중앙처리장치 혹은 저장장치와 같은 컴퓨터 자원들에게 작업을 나누는 것을 의미

<br>

### 로드밸런싱의 필요성
- 여러 대의 서버를 두고 서비스를 제공하는 분산 처리 시스템에서 필요한 기술
- 클라이언트 요청이 증가하여 기존 서버만으로는 정상적인 서비스가 불가능해지는데 증가한 <code>트래픽</code>을 대처할 수 있는 방법 중 Scale-out에 필요함

> 증가하는 트래픽에 대처하는 방법
> 1. Scale-up 
>       - 서버 자체의 성능을 확장하는 것. 서버 장비를 업그레이드
> 2. Scale-out 
>       - 기존 서버와 동일하거나 낮은 성능의 서버를 두 대 이상 증설하여 운영하는 것을 의미. 이 경우 여러 대의 서버로 트래픽을 균등하게 분산해주는 로드 밸런싱 기술이 필요
>
>```
> 트래픽(Traffic) : 서버나 스위치 등 네트워크 장치에서 일정 시간 내에 흐르는 데이터의 양을 말함. 웹 사이트에서의 트래픽은 사용자 접속에 따른 전송 데이터 양
>```

<br>

### 로드 밸런싱의 기본 기능
1. 상태 확인 (Health Check)
    - 서버들에 대한 주기적인 Health Check를 통해 서버들의 장애 여부를 판단하여, 정상 동작 중인 서버로만 트래픽을 보냄
    - L3 체크 : <code>ICMP</code>를 이용하여 서버의 IP 주소가 통신 가능한 상태인지 확인
    - L4 체크 : TCP는 3 Way-Handshaking을 기반으로 통신하는데 이러한 TCP의 특성을 바탕으로 각 포트 상태를 체크하는 방식
    - L7 체크 : 애플리케이션 계층에서 체크를 수행하여 실제 웹페이지에 통신을 시도하여 이상 유무 파악
    ```
    ICMP ( Internet Control Message Protocol) : 패킷 전송에 실패했을 때 에러가 났음을 알림과 동시에 해결 가능한 힌트를 제공하는 메시징 프로토콜. TCP/IP 계층에서 동작
    ```
2. 터널링 (Tunneling)
    - 데이터 스트림을 인터넷 상에서 가상의 파이프를 통해 전달시키는 기술로 패킷 내의 터널링할 대상을 캡슐화 시켜 목적지 까지 전송
    - 연결된 상호 간에만 캡슐화된 패킷을 구별해 캡슐화를 해제하게 함
3. NAT (Network Address Translation)
    - 내부 네트워크에서 사용하는 사설 IP 주소와 로드밸런서 외부의 공인 IP 주소 간의 변환 역할 ([NAT 설명 링크](./OSI_L4.md))
    - 로드밸런싱 관점에서는 여러 개의 호스트가 하나의 공인 IP 주소(VLAN or VIP)를 통해 접속하는 것이 주 목적
    - SNAT (Source Network Address Translation) : 내부에서 외부로 트래픽이 나가는 경우 내부 사설 IP주소 -> 외부 공인 IP 주소로 변환
    - DNAT (Destination Network Address Translation) : 외부에서 내부로 트래픽이 들어오는 경우 외부 공인 IP 주소 -> 내부 사설 IP 주소로 변환
4. DSR (Destination Network Address Translation)
    - 서버에서 클라이언트로 트래픽이 되돌아 가는 경우, 목적지를 클라이언트로 설정한 다음, 네트워크 장비나 로드밸런서를 거치지 않고 바로 클라이언트를 찾아가는 방식
    - 이 기능을 통해 로드밸런서의 부하를 줄여줄 수 있음

<br>

![Load Balancer](./img/loadbalancer.png)

<br>

### 로드밸런서 (Load Balancer)
- 서버에 가해지는 부하(로드)를 분산(밸런싱)해주는 장치 또는 컴퓨터 네트워크 기술의 통칭.
- 한 대의 서버로 부하가 집중되지 않도록 트래픽을 관리해 각각의 서버가 최적의 퍼포먼스를 보일 수 있도록 함
- 클라이언트와 네트워크 트래픽이 집중되는 서버들 또는 네트워크 허브 사이에 위치
- OSI 7계층은 상위 계층에서 사용되는 장비는 하위 계층의 장비가 가지는 기능을 모두 가지고 있어 상위 계층으로 갈수록 더욱 정교한 로드밸런싱 가능
- OSI 4계층인 전송계층의 L4 로드밸런서와 OSI 7계층인 애플리케이션 계층의 L7 로드밸런서가 가장 많이 활용되는데 L4 로드밸런서부터 포트 정보를 바탕으로 로드를 분산 가능하기 때문. 다수의 서버 프로그램을 운영하는 경우 최소 L4 로드밸런서 이상을 사용해야만 함
- L4는 단순히 부하를 분산, L7는 요청의 세부적인 사항을 두고 서비스별 서버로 분리하여 가볍고 작은 단위로 여러개의 서비스를 운영하고 요청을 각각의 서버에 분산 가능
- 특정기능이 필요한 것이 아니라면 <b>초당 연결수(Connections Per Sec), 동시 연결수(Concurrent Connections), 처리용량(Throughput)</b>을 성능 지표로 하여 L4 로드밸런서와 L7 로드밸런서중 적절히 선택하면 됨
>#### L4 Load Balancing
>- 서버나 네트워크의 트래픽을 로드밸런싱하는 스위치로 OSI 4계층인 '전송 계층'의 L4 스위치. 
>- TCP/IP 프로토콜을 기반으로 대부분 동작하여 Port 단위의 로드 밸런싱을 수행한다. 
>- L7에 비하여 속도가 빠르고 효율이 높고 가격이 저렴
>- 데이터의 내용을 복호화할 필요가 없어 안전
>- 패킷의 내용을 모르기 때문에 섬세한 라우팅이 불가능하고 사용자 IP가 수시로 바뀌는 경우라면 연속적인 서비스 제공이 어려움
>- TCP와 UDP의 헤더(Port)를 보고 적절한 서버로 스위칭 해줌
>- 주로 Round Robin 방식을 사용한다.
>- CLB(Connection Load Balancer) 또는 SLB(Session Load Balancer)라고 부르기도 함
>- 사용방식
>>- Round Robin(순차방식)
>>    - 요청을 순서대로 각 서버에 균등하게 분배하는 방식
>>    - 서버 커넥션 수나 응답시간에 상관없이 모든 서버를 동일하게 처리, 다른 알고리즘에 비해서 가장 빠름
>>- IP 해시 방식(IP Hash Method)
>>    - 클라이언트의 IP 주소를 특정 서버로 매핑하여 요청을 처리하는 방식
>>    - 사용자의 IP를 <code>해싱</code>하여 코드를 분배하기 때문에 사용자가 항상 동일한 서버로 연결되는 것을 보장
>>- 최소 접속 방식(Least Connection)
>>    - 서버에 연결되어 있는 Connection 개수만 갖고 단순 비교하여 가장 적은 곳에 연결
>>- 가중치 최소 접속 방식(Weighted Least Connection)
>>    - 서버에 부여된 Weight 값을 기반으로 Connection 수의 개수와 같이 고려하여 할당
>>- 응답 시간 방식(Fastest Response Time)
>>    - 가장 빨리 응답하는 서버에 이용자 요구를 연결하는 방법.
>>    - 응답시간은 각 서버가 패킷 형태의 요구를 송수신하는데 걸리는 시간을 측정
>>- 최소 대기 방식(Adaptive)
>>    - Open 또는 Pending(계류중) 커넥션을 적게 가지고 있는 서버로 네트웍 커넥션 방향을 지정.
>>    - Pending 커넥션은 Full TCP Handshake를 완성하지 않은 것으로, 이것은 초 마다 클라이언트 Thread 수가 증가할 때 더욱 잘 수행됨
>>- 대역폭 방식(Bandwidth Method)
>>    - 서버들과의 <code>대역폭</code>을 고려하여 서버에 트래픽을 할당
>>
>>```
>>해싱(Hashing) : 임의의 길이를 지닌 데이터를 고정된 길이의 데이터로 매핑하는 것, 또는 그러한 함수
>>
>>대역폭(Bandwidth) : 데이터가 한 위치에서 다른 위치로 전송될 수 있는 속도를 설명하는데 사용되는 용어로 보통 초당 비트수로 측정되며 사이트, 사용자 및 서버 간에 데이터를 전송하는 속도에 영향을 끼침
>>```
>
> <br>
>
>#### L7 Load Balancing
>- OSI 계층인 '애플리케이션 계층'의 L7 스위치
>- 애플리케이션 계층(HTTP,FTP,SMTP)에서 로드(부하)를 분산(밸런싱)하기 때문에 HTTP 헤더, 쿠키 등과 같은 사용자 요청을 기준으로 특정 서버에 트래픽을 분산. 즉, 패킷의 내용을 확인하고 그 내용에 따라 로드를 특정 서버에 분배하는 것이 가능. 그래서 콘텐츠 기반 스위칭이라고도 함.
>- 캐싱(Cashing)기능 제공
>- L7 로드밸런서의 경우 특정한 패턴을 지닌 바이러스를 감지해 네트워크 보호
>- DoS/DDoS 와 같은 비정상적인 트래픽을 필터링할 수 있어 그만큼 자원의 소모가 크지만 네트워크 보안 분야에서도 활용됨.
>- Port 단위의 로드밸런싱을 수행하는 L4를 극복하기 위해 Port 정보와 패킷의 <code>페이로드</code> 내용까지 분석하여 로드밸런싱을 수행.
>- L4에 비해 패킷의 내용을 복호화하여야 하므로 비쌈
>- 클라이언트가 로드밸런서와 인증서를 공유해야 하기 때문에 로드밸런서를 통해 클라이언트의 데이터에 접근할 수 있는 보안상 위험성 존재
>- 사용 방식
>>  - URL 스위칭 (URL Switching) 방식
>>      - 특정 하위 URL들은 특정 서버로 처리하는 방식
>>  - 컨텍스트 스위칭 (Context Switching) 방식
>>      - 클라이언트가 요청한 특정 리소스에 대해 특정 서버로 연결 가능
>>  - 쿠키 지속성 (Persistence with Cookies) 
>>      - 쿠키 정보를 바탕으로 클라이언트가 연결했었던 동일한 서버에 계속 할당
>>      - 특히 사설 네트워크에 있던 클라이언트의 IP주소가 공인 IP 주소로 치환되어 전송하는 방식을 지원
>>
>>``` 
>>페이로드 (payload) : 보내고자 하는 데이터 자체를 의미로 Message의 Body 부분에 해당
>>```

<br>

### AWS
#### 1. CLB (Classic Load Balancer)
- Layer4, Layer7 부하 분산
- listen : TCP, SSL/TLS, HTTP, HTTPS 
- 현재는 거의 사용되지 않음.

#### 2. ALB (Application Load Balancer)
- Layer7 부하 분산
- listen : HTTP, HTTPS, gRPC
- target : IP, Instance, Lambda
- 가장 기본적

#### 3. NLB (Network Load Balancer)
- Layer4 부하 분산
- listen : TCP, UDP, TLS
- target : IP, Instance
- 탁월한 성능

#### 4. GLB (Gateway Load Balancer)
- Layer3, Layer4 부하 분산
- listen : IP
- target : IP, Instance

<br>

## Ssafy Wizards CS Study

### 1. L4 로드밸런서와, L7 로드밸런서의 차이
#### L4 로드 밸런서
- OSI 모델의 4계층(Layer 4, 전송 계층)에서 동작
- IP 주소와 포트 번호를 기준으로 트래픽을 분산
- TCP/UDP 패킷의 헤더 정보를 바탕으로 로드 밸런싱을 수행하며, 패킷의 내용(데이터)에는 접근하지 않음
- 세션을 유지하지 않고, 클라이언트의 요청을 여러 서버로 분산시킴
- 빠르고 효율적이며, 트래픽 처리량이 큼
- 네트워크 계층에서 트래픽을 분산하므로, 상대적으로 시스템 리소스가 적게 소모됨
- 요청의 세부 내용(예: URL, 헤더, 쿠키 등)을 분석하거나 기반으로 라우팅하는 기능이 없음

#### L7 로드 밸런서
- OSI 모델의 7계층(Layer 7, 애플리케이션 계층)에서 동작
- HTTP/HTTPS 요청의 URL, 헤더, 쿠키, 메서드 등 애플리케이션 계층의 데이터를 분석하여 로드 밸런싱을 수행함
- 트래픽을 특정 서버로 라우팅하기 위해 컨텐츠 기반 라우팅을 할 수 있음. 특정 URL 요청은 특정 서버로 보내고, 다른 요청은 다른 서버로 보내는 것이 가능함
- 세션 유지 관리(로그인 세션 유지 같은) 등의 부가적인 기능을 제공
- 트래픽의 세부 내용을 분석하여 더 정교한 로드 밸런싱이 가능하고 특정 애플리케이션에 최적화된 로드 밸런싱을 수행할 수 있음
- 패킷의 내용까지 분석하므로, L4 로드밸런서에 비해 처리량이 낮고 시스템 리소스가 더 많이 필요
- 웹 애플리케이션, API 게이트웨이, SSL 오프로드, 콘텐츠 분배 네트워크(CDN) 등에서 자주 사용됨

<br>

| **특징**               | **L4 로드밸런서**                                   | **L7 로드밸런서**                                 |
|------------------------|-----------------------------------------------------|---------------------------------------------------|
| **동작 계층**          | OSI 4계층 (전송 계층)                                | OSI 7계층 (애플리케이션 계층)                     |
| **로드 밸런싱 기준**   | IP 주소, 포트 번호                                   | HTTP 헤더, URL, 쿠키, 메서드 등                   |
| **데이터 분석**        | 패킷 헤더만 분석, 페이로드는 분석하지 않음           | 애플리케이션 레벨에서 패킷 페이로드까지 분석      |
| **세션 유지**          | 세션 유지를 지원하지 않음                           | 세션 유지 가능 (예: 사용자 세션 유지)             |
| **처리 성능**          | 높은 처리량, 낮은 리소스 사용                        | 처리량 낮음, 높은 리소스 사용                     |
| **사용 사례**          | 게임 서버, VoIP, DNS                                | 웹 애플리케이션, API, SSL 오프로드                |


<br>

### 2. 로드밸런서 알고리즘
- 로드 밸런서가 클라이언트의 요청을 여러 서버에 어떻게 분배할지 결정하는 방식
- 로드 밸런싱은 서버 간의 트래픽 부하를 고르게 분산하여 시스템의 효율성을 높이고, 가용성을 보장하며, 서비스 응답 시간을 줄이기 위해 사용됨
- 각 알고리즘은 특정한 상황에서 유리하며, 서버의 성능, 부하, 클라이언트 요구 사항에 따라 적절한 알고리즘을 선택함
- 일반적으로 사용되는 알고리즘으로는 라운드 로빈, 최소 연결, IP 해시 등이 있으며, 각각의 알고리즘은 고유한 장점과 단점을 가지고 있음

<br>

#### 1. 라운드 로빈 (Round Robin)
- 서버에 순차적으로 요청을 분배하는 방식
- 간단하고 균등하게 분산 가능
- 서버 성능이나 부하를 고려하지 않음

#### 2. 가중치 라운드 로빈 (Weighted Round Robin)
- 서버마다 가중치를 부여하고, 가중치에 따라 요청을 분배
- 성능이 좋은 서버에 더 많은 요청을 할당
- 서버 성능의 동적 변화를 반영하지 못할 수 있음

#### 3. 최소 연결 (Least Connections)
- 현재 가장 적은 연결 수를 가진 서버에 요청을 할당
- 동적 부하 분산에 유리
- 연결 수가 적은 서버에 집중될 수 있음

#### 4. 가중치 최소 연결 (Weighted Least Connections)
- 최소 연결 알고리즘에 가중치를 추가하여 트래픽을 분배
- 서버 성능과 부하를 모두 반영
- 구현이 복잡할 수 있음

#### 5. IP 해시 (IP Hash)
- 클라이언트의 IP 주소를 해싱하여 특정 서버에 요청을 할당
- 동일한 IP 주소의 클라이언트는 항상 동일한 서버에 연결
- 서버 장애 시 트래픽 재분배가 어려울 수 있음

#### 6. 최소 응답 시간 (Least Response Time)
- 서버의 응답 시간을 기준으로, 가장 빠른 서버에 요청을 할당
- 효율적인 부하 분산 가능
- 응답 시간을 지속적으로 모니터링해야 함

#### 7. 최소 대기 시간 (Shortest Queue)
- 서버의 요청 대기열 길이를 기준으로, 가장 짧은 대기열을 가진 서버에 요청을 할당
- 전체 시스템의 응답 속도 개선
- 대기열 길이 모니터링 필요, 비효율적일 수 있음

#### 8. 랜덤 할당 (Random Allocation)
- 서버를 무작위로 선택하여 요청을 할당
- 구현이 매우 간단
- 서버 상태나 부하를 고려하지 않음, 비효율적일 수 있음

<br>

### 3. 로드밸런싱 대상이 되는 장치중 일부 장치가 문제가 생겨 접속이 불가능할 경우, 로드밸런서가 해당 장비로 요청을 보내지 않도록 하는 방법
- 주로 헬스 체크(Health Check) 또는 상태 점검(Health Monitoring) 기능을 활용
    - 로드 밸런서가 대상 서버나 장비의 상태를 주기적으로 점검하여, 정상적으로 작동하지 않는 서버를 트래픽 분산 대상에서 제외시키는 방법

#### 1. 헬스 체크
- 로드 밸런서는 일정 간격으로 대상 서버나 장비에 요청을 보내서 해당 장비가 정상적으로 작동하고 있는지 확인
- 헬스 체크는 여러 방법으로 수행될 수 있으며, HTTP, TCP, ICMP(Ping) 등을 통해 간단한 요청을 보내고, 응답이 오는지를 확인하는 방식이 일반적
    - HTTP : HTTP 요청을 보내 서버가 200 OK와 같은 정상적인 응답을 반환하는지 확인
    - TCP : TCP 연결을 시도하여 서버가 정상적으로 연결을 수락하는지 확인
    - ICMP : ICMP 패킷(Ping)을 보내서 서버가 응답하는지 확인

#### 2. 상태 점검 실패 처리
- 헬스 체크에 실패한 서버를 로드 밸런싱 대상에서 제외
- 서버가 다시 정상적인 응답을 보내면, 로드 밸런서는 이를 인식하고 해당 서버를 다시 로드 밸런싱 대상에 포함시킬 수 있음

#### 3. 주기적인 상태 점검
- 일정 간격으로 서버의 상태를 점검하여, 정상적인 서버만 트래픽을 받도록 설정
- 헬스 체크를 통해 문제가 있는 서버가 감지되면, 로드 밸런서는 해당 서버로의 트래픽을 중단하고, 나머지 정상적인 서버로 트래픽을 분산

#### 4. 자동 복구
- 서버가 다시 정상적인 상태가 되면 로드 밸런싱 대상에 자동으로 포함

<br>

#### 설정 예시
- nginx 의 경우 다음과 같음

```nginx
upstream backend {
    server backend1.example.com;
    server backend2.example.com;
    server backend3.example.com;

    # 헬스 체크 설정
    health_check interval=10s fails=3 passes=2;
}
```

- AWS Elastic Load Balancer (ELB)에서의 헬스 체크
    - 주기(Interval), 타임아웃(Time-out), 실패 임계값(Unhealthy threshold), 성공 임계값(Healthy threshold)을 설정하여 정상적인 서버만 로드 밸런싱에 포함되도록 설정할 수 있음

<br>

### 4. 로드밸런서 장치를 사용하지 않고, DNS를 활용해서 유사하게 로드밸런싱을 하는 방법
#### 1. DNS 라운드 로빈
- 여러 서버 IP를 순차적으로 반환하여 트래픽을 분산
- 이 방법은 여러 서버에 동일한 도메인 이름을 할당하고, DNS 서버가 요청마다 다른 서버의 IP 주소를 반환하도록 설정하는 방식으로 DNS 기반 로드 밸런싱 중에 가장 널리 사용되는 방법중 하나
- 간단한 설정으로 트래픽 분산
- 서버 상태를 고려하지 않음, 캐싱 문제 발생 가능

#### 2. GeoDNS
- 사용자 위치에 따라 가장 가까운 서버로 트래픽을 분산
- 사용자에게 가장 가까운 서버로 연결해 지연 시간 감소
- 설정이 복잡하고, 정확한 위치 판단이 어려울 수 있음

#### 3. DNS Failover
- 서버 장애 시 자동으로 다른 서버로 전환
- 서버 장애 시 자동으로 다른 서버로 전환
- 장애 감지에 시간이 걸릴 수 있으며, DNS 캐싱 문제 발생 가능

#### 4. Weighted DNS
- 서버 성능에 따라 가중치를 부여하여 트래픽 분산
- 서버 성능에 따라 트래픽을 비례적으로 분산
- 설정이 복잡하며, 모든 DNS 제공업체에서 지원하지 않음

#### 5. Anycast DNS
- 동일한 IP를 여러 위치에 할당하여 가장 가까운 서버로 트래픽 전달
- 자동으로 가장 가까운 서버로 트래픽을 전달해 빠른 응답
- 설정이 복잡하며, 주로 대규모 네트워크에 적합

#### 6. Latency-based Routing
- 지연 시간이 가장 짧은 서버로 트래픽을 라우팅
- 지연 시간이 가장 짧은 서버로 트래픽을 라우팅하여 성능 최적화
- 특정 DNS 제공업체에 종속될 수 있으며, 비용 발생 가능

#### 7. DNS Traffic Steering
- 조건에 따라 트래픽을 특정 서버로 분배
- 조건에 따라 유연하게 트래픽을 분배
- 구현과 관리가 복잡하며, 고급 DNS 서비스 필요

```
DNS 라운드 로빈 사용 방법
- DNS 라운드 로빈은 간단한 A 레코드 설정만으로 여러 서버에 트래픽을 분산시키는 방법
- 대부분의 DNS 서버 소프트웨어가 기본적으로 지원하며, TTL 설정을 통해 캐싱 문제를 조정할 수 있음
- 이 방법은 설정이 쉽고 효과적이지만, 서버 상태를 고려하지 않으므로 더 복잡한 로드밸런싱 요구사항이 있는 경우 다른 방법과 함께 사용하는 것이 좋음

1. 다중 A 레코드 생성
- 도메인에 대해 여러 개의 A 레코드를 생성. 각 A 레코드는 다른 서버의 IP 주소를 가리킴
- 이렇게 설정하면, DNS 서버는 example.com에 대한 쿼리를 받을 때마다 하나의 IP 주소를 반환. 어떤 IP 주소를 반환할지는 DNS 서버의 설정에 따라 순차적 또는 무작위로 결정함

2. DNS 서버 설정 확인
- 일반적인 DNS 서버 소프트웨어는 라운드 로빈 방식을 기본적으로 지원
- 특별한 설정 없이도 다중 A 레코드가 있는 경우 DNS 서버는 자동으로 라운드 로빈 방식으로 IP 주소를 반환함
- 만약 DNS 서버에서 라운드 로빈을 비활성화하거나 특정 순서를 강제하려면, DNS 서버의 설정 파일을 수정해야 할 수 있음

3. TTL (Time To Live) 설정
- TTL 값을 조정하여 DNS 캐싱의 영향을 최소화할 수 있음
- 낮은 TTL 값은 클라이언트가 DNS 쿼리를 자주 갱신하게 하여 더 균등한 트래픽 분배를 유도하지만, DNS 서버에 부하가 증가할 수 있음

4. 트래픽 모니터링
- 라운드 로빈이 제대로 작동하는지 확인하려면, 각 서버의 트래픽을 모니터링하여 트래픽이 균등하게 분산되는지 확인
- 불균형이 발생하는 경우, TTL 값을 조정하거나, 가중치 기반의 라운드 로빈(Weighted DNS) 등을 고려할 수 있음
```

<br>

<div style="text-align: right">22-06-29</div>

<br>

## Reference
- https://devfunny.tistory.com/630
- https://velog.io/@makeitcloud/란-L4-load-balancer-vs-L7-load-balancer-란
- https://co-no.tistory.com/22
- https://www.stevenjlee.net/2020/06/30/이해하기-네트워크의-부하분산-로드밸런싱-load-balancing-그/
- https://jaehoney.tistory.com/73